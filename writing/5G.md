---
title: 5G
tags: physics, computers
date: 2020-04-04
abstract: What's the issue with 5G?
---

Do you actually know what 5G is? As a software engineer, and (lapsed) computer science researcher, I know a number of individuals who were involved in the design and development of the 5G protocol, and I have a somewhat detailed understanding of the theory and practice behind it, so let me try and break it down for you.

5G, at its simplest, is simply a protocol, or language, which mobile devices can use to communicate with each other. It has no "physical" existence as such, but is simply a description of one method that computers can use to send messages to each other. The 5G specification (i.e. the set of rules that govern the language that computers use to speak to each other) states that it uses radio waves to perform the communication, but I want you to be aware that this is *separate* from "5G" itself. 5G does not *depend* on radio waves for it to work: If you wanted to (and if you had limitless amounts of time), you could "perform" a 5G connection with me by simply sending hand-written messages back and forth.

In reality, however, 5G does use radio waves. It can use the same wavelengths of radio as the previous generation protocol (4G) with no changes, or be deployed using so called “millimetre wave” frequencies. This aspect of 5G is the *only* "physical" difference from previous wireless communication protocols (an aside: 5G stands for "fifth generation", and is an improvement on 4G, the "fourth generation" protocol). I suspect that, given that you have raised no concerns about 4G thus far in this conversation, your concern is with the millimetre wave version.

To give you a quick bit of fundamental physics as background, radio waves (like all waves) can be measured using four values: their speed, their frequency, their wavelength, and their amplitude. Radio waves are just another form of light, so their speed (in air at least) is constant: around 300,000,000 meters per second. Given the speed is constant, the wavelength and frequency can be considered as a single value, as they are related by the formula: `wavelength = speed / frequency`. Given that speed is constant, we can replace it with "c", and get the proportional relationship "wavelength = c / frequency". Amplitude simply refers to how "strong" of the radio wave is - or how much energy it carries. In waves in the sea, this would be the height of the wave, and in visible light (a kind of radio wave), it would be the brightness of the light.

Finally, we need to talk about attenuation. Attenuation is a complicated word for a simple concept - how quickly does a wave lose power as it travels. For example, if you drop a bowling ball into a calm swimming pool, the initial wave will be really big, but as it travels it loses energy, and by the time it reaches the other end it will be much smaller. This is because as the wave travels it spreads out and loses energy by propagation. By spreading out it spreads the same amount of energy over a larger area (hence each small bit of the wave gets less energy), and it loses energy to other things it encounters along the way (for example the friction of the sides of the swimming pool).

Radio waves also attenuate as they travel along, in much the same way. Firstly, they lose energy by spreading out - this is why the sun looks *really* bright to us, while stars look really dim and weak. The sun is much closer, so the energy hasn't spread out as far by the time it reaches us, while stars (although much more energyful than our sun!) are much further away, so we get a much smaller amount of their energy. Radio waves also lose energy as they pass through materials, or are reflected or refracted. This is how sunglasses work: they take away some of the energy of the incoming light so that it's less bright. Your WiFi works the same way, which is why you get great signal close to the router, but much worse signal behind a wall.

Finally, attenuation is also a product of the *frequency* of the wave (and therefore the wavelength). This is a little more complicated than the previous physics, but I'll do my best. Put simply, very low frequency waves (high wavelength) lose energy more slowly as they travel, while high frequency (low wavelength) waves lose it very quickly. This is why whales communicate using deep "moaning" sounds - the low frequency (high wavelength) sounds travel very very far underwater, as they lose less energy, which allows other whales to hear them. Similarly, at high enough frequencies (very small wavelengths), some materials can completely *block* the waves. Visible light is a great example of a very high frequency radio wave, with a very very small wavelength, and it is blocked easily with a piece of paper, or your hand. A much lower frequency (higher wavelength) wavelength, such as your WiFi will pass right through it, which is why you can use your phone on the WiFi even when you're holding it.

I'm diving into this much fundamental physics background, because this fundamental background is the only thing that separates 4G, and 5G as far as this conversation is concerned. (The other protocol differences are purely non-physical, and are simply differences in code running on computers.)

The 5G specification allows for the use of "millimeter wave" frequencies. What this means is that the wavelength of the radio waves used for the 5G connection are roughly the size of a millimeter. As the wavelength is inversely proportional to the frequency, this means that "millimeter wave" signals are very high frequency, and can therefore carry a lot of data. As we saw before though, very high frequency signals attenuate very quickly, so this aspect of 5G has to be deployed very carefully and specifically, as the waves are blocked by a few tens of meters of air, or the walls of a building. Very few 5G installations currently use these frequencies, as they are costly to install, and need to be placed deliberately so that the signals can actually reach where they need to go.

Now, millimeter-and-below wavelengths of radio waves can be harmful, that is true. The microwaves that we use to reheat our pasta are high-energy, short wavelength radio waves, and I'm sure none of us are particularly keen to put our heads in a microwave. These radio waves *can* be dangerous because they can easily transfer energy to our bodies in ways that may be harmful, because (as they are high frequency) they lose energy quickly as they travel, and they might lose that energy into *us*.

However, as anyone who's ever chowed down on some partially-defrosted soup would ever tell you, high-frequency wavelengths like microwaves can easily become useless if directed badly, or when there is too much mass in the way into which they lose energy. Some materials can even block them entirely - moist air being a good one. This is why microwaves are safe to use in our house, because they have shielding around them that blocks the radio waves. However, even if we removed the shielding, we wouldn't need to go more than a about 10 meters away, or behind a wall, to block the signals entirely (or at least, to a point where they don't harm us at all).

So, with that in mind, let's look into what the dangers are of this kind of signal! We've learned that:
- These signals don't go very far.
- They are blocked by almost anything, and
- They lose energy very very quickly.

For communication, those three are absolutely fine - radio antennas on phones are specifically designed to pick out the signals from "millimeter wave" radio, which means that they need very little energy from a wave in order to detect a signal. This level of energy is significantly less than what is required to cause any measurable change to your body - it's comparable to the energy that you would receive from a light-bulb in your living room. In many ways, the antennas that will be deployed for "millimeter wave" 5G are comparable to your neighbour installing an un-shielded microwave on the top of their house. Although it is a source of high-energy radio waves, by the time they get to you, your garden, and *especially* the inside of your house they will have lost so much energy that it would require specialized equipment (for example an antenna tuned to their frequency) to detect them.

Worrying about millimeter wave 5G is equivalent to hoping that your neighbours roof-microwave will be able to cook your pasta in your living room for you.

I'm kind of running out of steam here, but I hope if you've got this far you have some better understanding of what 5G actually *is*, and how the physics behind the one part of it that is actually physically different to what we have *now* with 4G. If you have any other questions, I'd be more than happy to answer them.